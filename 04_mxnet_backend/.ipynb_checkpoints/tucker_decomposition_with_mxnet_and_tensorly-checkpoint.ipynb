{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n",
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import MXNet\n",
    "from mxnet import nd, autograd\n",
    "import mxnet as mx\n",
    "\n",
    "# Import TensorLy\n",
    "import tensorly as tl\n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "from tensorly.random import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the backend to MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using mxnet backend.\n"
     ]
    }
   ],
   "source": [
    "tl.set_backend('mxnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker decomposition using SGD and autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just fix the random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234\n",
    "rng = check_random_state(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [5, 5, 5]\n",
    "\n",
    "tensor = tl.tensor(rng.random_sample(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a random Tucker decomposition of that tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [5, 5, 5]\n",
    "\n",
    "core = tl.tensor(rng.random_sample(ranks))\n",
    "factors = [tl.tensor(rng.random_sample((tensor.shape[i], ranks[i]))) for i in range(tensor.ndim)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the magic happens: we can attach gradients to the tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "core.attach_grad()\n",
    "for f in factors:\n",
    "    f.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the simplest possible learning method: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just iterate through the training loop and backpropagate... \n",
    "\n",
    "You might have seen such loop in the Gluon tutorials -- if not, check them out! \n",
    "https://github.com/zackchase/mxnet-the-straight-dope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000,. Rec. error: 0.347279879522\n",
      "Epoch 2000,. Rec. error: 0.278443677975\n",
      "Epoch 3000,. Rec. error: 0.247618797548\n",
      "Epoch 4000,. Rec. error: 0.22599700906\n",
      "Epoch 5000,. Rec. error: 0.210141688389\n",
      "Epoch 6000,. Rec. error: 0.199405938799\n",
      "Epoch 7000,. Rec. error: 0.191912010837\n",
      "Epoch 8000,. Rec. error: 0.185513961026\n",
      "Epoch 9000,. Rec. error: 0.179243347001\n",
      "Epoch 10000,. Rec. error: 0.172699493971\n",
      "Epoch 11000,. Rec. error: 0.16559772863\n",
      "Epoch 12000,. Rec. error: 0.157599658769\n",
      "Epoch 13000,. Rec. error: 0.148224595152\n",
      "Epoch 14000,. Rec. error: 0.136828442124\n",
      "Epoch 15000,. Rec. error: 0.122807826415\n",
      "Epoch 16000,. Rec. error: 0.106519898169\n",
      "Epoch 17000,. Rec. error: 0.0904362832508\n",
      "Epoch 18000,. Rec. error: 0.0770750992197\n",
      "Epoch 19000,. Rec. error: 0.0665911924915\n",
      "Epoch 20000,. Rec. error: 0.0581581413731\n",
      "Epoch 21000,. Rec. error: 0.0510929855842\n",
      "Epoch 22000,. Rec. error: 0.0450363862519\n",
      "Epoch 23000,. Rec. error: 0.0398456307076\n",
      "Epoch 24000,. Rec. error: 0.0354543345719\n",
      "Epoch 25000,. Rec. error: 0.0317942539636\n",
      "Epoch 26000,. Rec. error: 0.0287780891016\n",
      "Epoch 27000,. Rec. error: 0.026309485577\n",
      "Epoch 28000,. Rec. error: 0.0242954186154\n",
      "Epoch 29000,. Rec. error: 0.0226531260253\n",
      "Epoch 30000,. Rec. error: 0.0213122936261\n",
      "Epoch 31000,. Rec. error: 0.0202147093818\n",
      "Epoch 32000,. Rec. error: 0.0193128971463\n",
      "Epoch 33000,. Rec. error: 0.0185684854238\n",
      "Epoch 34000,. Rec. error: 0.0179506356\n",
      "Epoch 35000,. Rec. error: 0.017434649702\n",
      "Epoch 36000,. Rec. error: 0.0170007877685\n",
      "Epoch 37000,. Rec. error: 0.0166332872269\n",
      "Epoch 38000,. Rec. error: 0.0163195622391\n",
      "Epoch 39000,. Rec. error: 0.0160495568964\n"
     ]
    }
   ],
   "source": [
    "n_iter = 40000\n",
    "lr = 0.0005\n",
    "penalty = 0.1\n",
    "for i in range(1, n_iter):\n",
    "    \n",
    "    with autograd.record():\n",
    "        \n",
    "        # Reconstruct the tensor from the decomposed form\n",
    "        rec = tucker_to_tensor(core, factors)\n",
    "        \n",
    "        # l2 loss \n",
    "        loss = nd.sum((rec - tensor)**2)\n",
    "\n",
    "        # l2 penalty on the factors of the decomposition\n",
    "        for f in factors:\n",
    "            loss = loss + penalty * nd.sum(f**2)\n",
    "\n",
    "    loss.backward()\n",
    "    SGD([core] + factors, lr)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        rec_error = tl.norm(rec - tensor, 2)/tl.norm(tensor, 2)\n",
    "        print(\"Epoch %s,. Rec. error: %s\" % (i, rec_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
